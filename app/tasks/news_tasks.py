"""æ–°é—»ç›¸å…³çš„å®šæ—¶ä»»åŠ¡"""

from datetime import date, timedelta

from loguru import logger

from app.core.database import async_session
from app.core.scheduler import scheduler_manager
from app.services.news_service import NewsService


async def scrape_today_news():
    """å®šæ—¶ä»»åŠ¡ï¼šæŠ“å–ä»Šæ—¥æ–°é—»è”æ’­æ•°æ®

    ä»»åŠ¡è¯´æ˜ï¼š
    - æ¯å¤©è‡ªåŠ¨æŠ“å–å½“å¤©çš„æ–°é—»è”æ’­å†…å®¹
    - å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡
    - è‡ªåŠ¨å¤„ç†å¼‚å¸¸ï¼Œä¸å½±å“å…¶ä»–ä»»åŠ¡
    """
    try:
        today = date.today()
        logger.info("=" * 60)
        logger.info(f"ğŸ¤– å®šæ—¶ä»»åŠ¡è§¦å‘ï¼šæŠ“å–ä»Šæ—¥æ–°é—»ï¼ˆ{today}ï¼‰")
        logger.info("=" * 60)

        async with async_session() as session:
            news_service = NewsService(session)
            news_articles = await news_service.fetch_and_save_daily_news(today)

        logger.info(f"âœ“ å®šæ—¶ä»»åŠ¡å®Œæˆï¼šæˆåŠŸå¤„ç† {len(news_articles)} æ¡æ–°é—»")

    except Exception as e:
        logger.error(f"âŒ å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼šæŠ“å–ä»Šæ—¥æ–°é—»æ—¶å‡ºé”™ - {str(e)}", exc_info=True)


async def scrape_yesterday_news():
    """å®šæ—¶ä»»åŠ¡ï¼šæŠ“å–æ˜¨æ—¥æ–°é—»è”æ’­æ•°æ®

    ä»»åŠ¡è¯´æ˜ï¼š
    - è¡¥å……æŠ“å–æ˜¨æ—¥çš„æ–°é—»æ•°æ®ï¼ˆé˜²æ­¢å½“å¤©æœªæˆåŠŸæŠ“å–ï¼‰
    - å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡
    """
    try:
        yesterday = date.today() - timedelta(days=1)
        logger.info("=" * 60)
        logger.info(f"ğŸ¤– å®šæ—¶ä»»åŠ¡è§¦å‘ï¼šæŠ“å–æ˜¨æ—¥æ–°é—»ï¼ˆ{yesterday}ï¼‰")
        logger.info("=" * 60)

        async with async_session() as session:
            news_service = NewsService(session)
            news_articles = await news_service.fetch_and_save_daily_news(yesterday)

        logger.info(f"âœ“ å®šæ—¶ä»»åŠ¡å®Œæˆï¼šæˆåŠŸå¤„ç† {len(news_articles)} æ¡æ–°é—»")

    except Exception as e:
        logger.error(f"âŒ å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼šæŠ“å–æ˜¨æ—¥æ–°é—»æ—¶å‡ºé”™ - {str(e)}", exc_info=True)


async def scrape_recent_week_news():
    """å®šæ—¶ä»»åŠ¡ï¼šæ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨çš„æ–°é—»æ•°æ®

    ä»»åŠ¡è¯´æ˜ï¼š
    - æ¯å‘¨æ‰§è¡Œä¸€æ¬¡ï¼Œè¡¥å……æœ€è¿‘ 7 å¤©çš„æ–°é—»æ•°æ®
    - ç¡®ä¿æ•°æ®å®Œæ•´æ€§
    """
    try:
        logger.info("=" * 60)
        logger.info("ğŸ¤– å®šæ—¶ä»»åŠ¡è§¦å‘ï¼šæ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨æ–°é—»")
        logger.info("=" * 60)

        today = date.today()
        success_count = 0
        skip_count = 0

        for i in range(7):
            target_date = today - timedelta(days=i)

            async with async_session() as session:
                news_service = NewsService(session)
                existing_count = await news_service.get_news_count_by_date(target_date)

                if existing_count > 0:
                    logger.info(
                        f"è·³è¿‡ {target_date}ï¼šæ•°æ®åº“å·²æœ‰ {existing_count} æ¡æ–°é—»"
                    )
                    skip_count += 1
                    continue

                news_articles = await news_service.fetch_and_save_daily_news(
                    target_date
                )
                if news_articles:
                    success_count += 1
                    logger.info(
                        f"âœ“ æˆåŠŸæŠ“å– {target_date}ï¼š{len(news_articles)} æ¡æ–°é—»"
                    )

        logger.info("=" * 60)
        logger.info(f"âœ“ æ‰¹é‡ä»»åŠ¡å®Œæˆï¼šæˆåŠŸ {success_count} å¤©ï¼Œè·³è¿‡ {skip_count} å¤©")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ å®šæ—¶ä»»åŠ¡å¤±è´¥ï¼šæ‰¹é‡æŠ“å–æ–°é—»æ—¶å‡ºé”™ - {str(e)}", exc_info=True)


def register_news_tasks():
    """æ³¨å†Œæ‰€æœ‰æ–°é—»ç›¸å…³çš„å®šæ—¶ä»»åŠ¡

    ä»»åŠ¡è°ƒåº¦è¯´æ˜ï¼š
    1. æ¯å¤© 20:30 æŠ“å–ä»Šæ—¥æ–°é—»ï¼ˆæ–°é—»è”æ’­æ’­å‡ºåï¼‰
    2. æ¯å¤© 08:00 è¡¥å……æŠ“å–æ˜¨æ—¥æ–°é—»ï¼ˆç¡®ä¿æ•°æ®å®Œæ•´ï¼‰
    3. æ¯å‘¨æ—¥ 02:00 æ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨æ•°æ®ï¼ˆæ•°æ®ä¿®å¤ï¼‰
    """
    scheduler = scheduler_manager.scheduler

    # ä»»åŠ¡ 1ï¼šæ¯å¤© 20:30 æŠ“å–ä»Šæ—¥æ–°é—»
    scheduler.add_job(
        scrape_today_news,
        trigger="cron",
        hour=20,
        minute=30,
        id="scrape_today_news",
        name="æŠ“å–ä»Šæ—¥æ–°é—»è”æ’­",
        replace_existing=True,
    )
    logger.info("âœ“ å·²æ³¨å†Œä»»åŠ¡ï¼šæŠ“å–ä»Šæ—¥æ–°é—»ï¼ˆæ¯å¤© 20:30ï¼‰")

    # ä»»åŠ¡ 2ï¼šæ¯å¤© 08:00 è¡¥å……æŠ“å–æ˜¨æ—¥æ–°é—»
    scheduler.add_job(
        scrape_yesterday_news,
        trigger="cron",
        hour=8,
        minute=0,
        id="scrape_yesterday_news",
        name="æŠ“å–æ˜¨æ—¥æ–°é—»è”æ’­",
        replace_existing=True,
    )
    logger.info("âœ“ å·²æ³¨å†Œä»»åŠ¡ï¼šæŠ“å–æ˜¨æ—¥æ–°é—»ï¼ˆæ¯å¤© 08:00ï¼‰")

    # ä»»åŠ¡ 3ï¼šæ¯å‘¨æ—¥ 02:00 æ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨æ•°æ®
    scheduler.add_job(
        scrape_recent_week_news,
        trigger="cron",
        day_of_week="sun",
        hour=2,
        minute=0,
        id="scrape_recent_week_news",
        name="æ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨æ–°é—»",
        replace_existing=True,
    )
    logger.info("âœ“ å·²æ³¨å†Œä»»åŠ¡ï¼šæ‰¹é‡æŠ“å–æœ€è¿‘ä¸€å‘¨æ–°é—»ï¼ˆæ¯å‘¨æ—¥ 02:00ï¼‰")

    logger.info("=" * 60)
    logger.info("ğŸ¯ æ‰€æœ‰æ–°é—»å®šæ—¶ä»»åŠ¡æ³¨å†Œå®Œæˆ")
    logger.info("=" * 60)
